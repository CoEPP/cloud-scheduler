#!/usr/bin/env python
# vim: set expandtab ts=4 sw=4:

# Copyright (C) 2009 University of Victoria
# You may distribute under the terms of either the GNU General Public
# License or the Apache v2 License, as specified in the README file.

## Auth: Duncan Penfold-Brown. 6/15/2009

## CLOUD SCHEDULER
##
## The main body for the cloud scheduler, that encapsulates and organizes
## all cloud scheduler functionality.
##
## Using optparse for command line options (http://docs.python.org/library/optparse.html)
##

## Imports
import sys

if sys.version_info[:2] < (2,5):
    print "You need at least Python 2.5 to run Cloud Scheduler"
    sys.exit(1)

import os
import time
import string
import getopt
import signal
import logging
import threading
import ConfigParser
import logging.handlers
from optparse import OptionParser
from decimal import *

import cloudscheduler.config as config
import cloudscheduler.utilities as utilities
import cloudscheduler.__version__ as version
import cloudscheduler.info_server as info_server
import cloudscheduler.cloud_management as cloud_management
import cloudscheduler.job_management as job_management

#from cloudscheduler.monitoring.get_clouds import getCloudsClient

log = utilities.get_cloudscheduler_logger()

# Threaded Classes

class VMPoller(threading.Thread):
    """
    VMPoller - Polls all the requested VMs, and checks on their status
    """
    def __init__(self, resource_pool):
        threading.Thread.__init__(self)
        self.resource_pool = resource_pool
        self.quit          = False
        self.starting_poll_interval = 120 # 2 minutes
        self.running_poll_interval = 900 # 15 minutes
        self.run_interval = 5 # seconds

    def stop(self):
        log.debug("Waiting for VM polling loop to end")
        self.quit = True

    def run(self):
        log.info("Starting VM polling...")

        while not self.quit:
            self.poll_all_machines()
            sleep_tics = self.run_interval
            while (not self.quit) and sleep_tics > 0:
                time.sleep(1)
                sleep_tics -= 1
            

    def poll_all_machines(self):
        """
        poll_all_machines - internal function to poll all running VMs,
                            and then update their status
        """
        log.debug("Polling all running VMs...")
        for cluster in self.resource_pool.resources:
            for vm in cluster.vms:
                now = int(time.time())

                if vm.lastpoll and (vm.status == "Starting" and now - vm.lastpoll < self.starting_poll_interval):
                    log.debug("Skip polling %s, which has status %s" % (vm.id, vm.status))
                    continue
                elif vm.lastpoll and (vm.status == "Running" and now - vm.lastpoll < self.running_poll_interval):
                    log.debug("Skip polling %s, which has status %s" % (vm.id, vm.status))
                    continue

                ret_state = cluster.vm_poll(vm)

                # Print polled VM's state and details
                log.debug("Polled VM: ")
                vm.log_dbg()

                # If the VM is in an error state, keep track of error and
                # after passing some threshold destroy the machine.
                # Decrementing to avoid a long running VM from accumulating periodic
                # errors and being destroyed
                if ret_state == "Error":
                    vm.errorcount += 1
                elif vm.errorcount > 0:
                    vm.errorcount = 0
                if vm.errorcount >= config.polling_error_threshold:
                    log.info("VM %s in error state. Destroying..." % vm.name)

                    # Destroy the VM
                    destroy_ret = cluster.vm_destroy(vm)
                    if (destroy_ret != 0):
                        log.error("Destroying VM failed. Leaving VM in error state.")
                        continue


class JobPoller(threading.Thread):
    """
    JobPoller - Polls the Condor schedd for job status, and new jobs
    """

    def __init__(self, job_pool):
        threading.Thread.__init__(self)
        self.job_pool = job_pool
        self.quit = False
        self.polling_interval = 5 # seconds

    def stop(self):
        log.debug("Waiting for job polling loop to end")
        self.quit = True

    def run(self):
        log.info("Starting job polling...")

        while not self.quit:
            log.debug("Polling job scheduler")

            ## Query the job pool to get new unscheduled jobs
            # Populates the 'jobs' and 'scheduled_jobs' lists appropriately
            condor_jobs = self.job_pool.job_querySOAP()
            if condor_jobs != None:
                self.job_pool.update_jobs(condor_jobs)
            else:
                log.error("Failed to contact Condor job scheduler. Continuing with VM management.")
            del condor_jobs

            log.debug("Job Poller waiting %ds..." % self.polling_interval)
            sleep_tics = self.polling_interval
            while (not self.quit) and sleep_tics > 0:
                time.sleep(1)
                sleep_tics -= 1

        log.debug("Exiting job polling thread")

class Scheduler(threading.Thread):
    """
    Scheduler thread matches jobs to available resources, and starts
    VMs for them
    """
    ## Condor Job Status mapping 
    NEW      = 0
    IDLE     = 1
    RUNNING  = 2
    REMOVED  = 3
    COMPLETE = 4
    HELD     = 5
    ERROR    = 6

    def __init__(self, resource_pool, job_pool):
        threading.Thread.__init__(self)
        self.resource_pool = resource_pool
        self.job_pool      = job_pool
        self.quit          = False
        self.scheduling_interval = 5 # seconds
        self.starting_poll_interval = 120 # 2 minutes
        self.running_poll_interval = 900 # 15 minutes

    def stop(self):
        log.debug("Waiting for scheduling loop to end")
        self.quit = True

    def run(self):
        log.info("Starting job scheduling...")
        prevMachineList = []
        ########################################################################
        ## Full scheduler loop
        ########################################################################

        while not self.quit:
            log.debug("### Scheduler Cycle:")

            ## Check that jobs are valid for the clusters available
            bad_jobs = []
            for user in self.job_pool.new_jobs.keys():
                for job in self.job_pool.new_jobs[user]:
                    if not self.resource_pool.resourcePF(job.req_network, job.req_cpuarch):
                        bad_jobs.append(job)
            if not self.job_pool.write_lock.acquire():
                log.debug("remove bad jobs couldn't get a write lock on the job lists")
            else:
                try:            
                    while len(bad_jobs) > 0:
                        self.job_pool.remove_system_job(bad_jobs.pop())
                finally:
                    self.job_pool.write_lock.release()

            ## Figure out distribution of VMs requested and available
            current_types = {}
            if config.scheduling_metric == "slot":
                current_types = self.resource_pool.vmtype_distribution()
            if config.scheduling_metric == "memory":
                current_types = self.resource_pool.vmtype_mem_distribution()

            desired_types = self.job_pool.job_type_distribution()

            # Negative difference means will need to create that type
            diff_types = {}
            for type in current_types.keys():
                if type in desired_types.keys():
                    diff_types[type] = current_types[type] - desired_types[type]
                else:
                    diff_types[type] = 0
            for type in desired_types.keys():
                if type not in current_types.keys():
                    diff_types[type] = -desired_types[type]
            del desired_types
            del current_types

            ## Schedule user jobs
            # TODO: This should be less explicit in its reference to JobPool class parts.
            #       Something like 'for job in self.job_pool.get_unsched_jobs()'
            log.debug("Attempt to schedule user jobs")
            for user in self.job_pool.new_jobs.keys():

                # Attempt to schedule jobs in order of their appearance in user's job list
                # (currently sorted by Job priority)
                for job in self.job_pool.new_jobs[user]:
                    # Check that type of VM for job is needed
                    if job.req_vmtype in diff_types.keys() and diff_types[job.req_vmtype] <= 0:
                        # Do not start VMs for jobs in a Hold state
                        if job.job_status == self.HELD:
                            continue
                        # Find resources that match the job's requirements
                        (pri_rsrc, sec_rsrc) = self.resource_pool.get_resourceBF(job.req_network, \
                        job.req_cpuarch, job.req_memory, job.req_cpucores, job.req_storage)
                        
                        good_resources = [pri_rsrc]
                        if sec_rsrc and pri_rsrc != sec_rsrc:
                            good_resources.append(sec_rsrc)

                        # If no resource fits, continue to next job in user's list
                        if good_resources[0] == None:
                            log.info("No resource to match job: %s" % job.id)
                            log.info("Leaving job unscheduled, moving to %s's next job" % user)
                            continue

                        create_ret = self.vm_creation(job, good_resources)
                        if create_ret == 0:
                            # Mark job as scheduled
                            self.job_pool.schedule(job)
                        else:
                            continue
                        # break out of this user's job and try next user
                        break
                    else:
                        # This user already has their share
                        break
                # ENDFOR - for jobs in user's unscheduled job set
            #ENDFOR - Attempt to schedule each one job per user


            ## Clear all un-needed VMs from the system
            log.debug("Clearing all un-needed VMs from the system")

            # Count the number of jobs that require a certain VM type,
            # and then destroy the EXCESS VMs in that type TODO: leave a few for spare?
            log.debug("Gathering required VM types.")
            required_vmtypes = self.job_pool.get_required_vmtypes()

            machineList = self.resource_pool.resource_querySOAP()
            if machineList:
                # Make sure VMs have registered with Condor
                unregisteredvms = []
                for cluster in self.resource_pool.resources:
                    for vm in cluster.vms:
                        foundvm = False
                        if vm.status == 'Running':
                            host = vm.hostname.split('.')[0]
                            for machine in machineList:
                                condName = machine['Name'].split('.')[0]
                                if condName == host:
                                    foundvm = True
                                    break
                            if not foundvm:
                                unregisteredvms.append(vm)
                to_kill = []
                for vm in unregisteredvms:
                    # now -state change will be how long VM 'running'
                    running_time = int(time.time()) - vm.last_state_change
                    if running_time > config.condor_register_time_limit:
                        to_kill.append(vm)
                for machine in to_kill:
                    killedIt = False
                    for cluster in self.resource_pool.resources:
                        for vm in cluster.vms:
                            if vm == machine:
                                log.debug("Shutting down VM that has not registered with Condor after %i" % (config.condor_register_time_limit))
                                cluster.vm_destroy(machine)
                                killedIt = True
                                break
                        if killedIt:
                            break


                available_vmtypes_dict = self.resource_pool.get_vmtypes_count(machineList)
                required_vmtypes_dict = self.job_pool.get_required_vmtypes_dict()
                # Remove excess VMs when available VM type exceedes required by jobs
                log.debug("Removing excess VMs from the system.")
                to_remove = {}
                for vmtype, count in available_vmtypes_dict.iteritems():
                    if vmtype in required_vmtypes_dict.keys():
                        if count > required_vmtypes_dict[vmtype]:
                            to_remove[vmtype] = count - required_vmtypes_dict[vmtype]
                    # This type no longer needed, remove all remaining
                    else:
                        to_remove[vmtype] = count
                del available_vmtypes_dict
                del required_vmtypes_dict
                # Go over the types and find idle machines to remove
                self.remove_idle_machines(machineList, to_remove)

                # Balancing Resources
                num_to_change = {}
                vm_count = self.resource_pool.vm_count()
                for vmtype, val in diff_types.iteritems():
                    num_to_change[vmtype] = int(round(val * vm_count))

                if config.graceful_shutdown:
                    #TODO graceful shutdown via hold / release
                    for vmtype in diff_types.keys():
                        if diff_types[vmtype] > Decimal('0.1'):
                            self.job_pool.hold_vmtype(vmtype)
                        else:
                            self.job_pool.release_vmtype(vmtype)
                    self.remove_idle_machines(machineList, num_to_change)
                    # TODO Check for the idle machines to shutdown
                else:
                    # Compare current Machine List with Previous
                    # Looking for machines that have changed jobs since last check
                    # and are of a type that has an higher than wanted distribution
                    # based on diff_types
                    vm_matches = []
                    vm_starting = []
                    changed = self.resource_pool.machine_jobs_changed(machineList, prevMachineList)
                    for cluster in self.resource_pool.resources:
                        for vm in cluster.vms:
                            if vm.hostname in changed:
                                vm_matches.append(vm)
                            if vm.status == "Starting":
                                vm_starting.append(vm)
                    to_shutdown = []

                    for vm in vm_starting:
                        if vm.vmtype in num_to_change.keys() and num_to_change[vm.vmtype] > 0:
                            to_shutdown.append(vm)
                            num_to_change[vm.vmtype] -= 1
                    for vm in vm_matches:
                        if vm.vmtype in num_to_change.keys() and num_to_change[vm.vmtype] > 0:
                            to_shutdown.append(vm)
                            num_to_change[vm.vmtype] -= 1
                    for vm in to_shutdown:
                        log.debug("Shutting down VM of type %s to rebalance resources" % vm.vmtype)
                        cluster = self.resource_pool.get_cluster_with_vm(vm)
                        log.debug("VM %s on cluster %s shutting down" % (vm.name, cluster.name))
                        destroy_ret = cluster.vm_destroy(vm)
                        if destroy_ret != 0:
                            log.error("Destroying VM failed in attempt to redistribute VMs. Leaving VM.")

                prevMachineList = machineList
            else:
                log.debug("No Machines returned by Condor Collector Query")

            self.resource_pool.save_persistence()

            ## Wait for a number of seconds
            log.debug("Scheduler - Waiting %ss" % self.scheduling_interval)
            sleep_tics = self.scheduling_interval
            while (not self.quit) and sleep_tics > 0:
                time.sleep(1)
                sleep_tics -= 1

            # ENDFOR - For each cluster in the resource pool
        # ENDWHILE - End of the main scheduler loop

        # Exit the scheduling thread - clean up VMs and exit
        log.debug("Exiting scheduler thread")

        # Destroy all VMs and finish
        remaining_vms = []
        log.debug("### Destroying all remaining VMs and exiting :-(")
        for cluster in self.resource_pool.resources:
            i = len(cluster.vms)
            while (i != 0):
                i = i-1

                log.debug("Destroying VM:")
                cluster.vms[i].log
                destroy_ret = cluster.vm_destroy(cluster.vms[i])
                if destroy_ret != 0:
                    log.error("Destroying VM failed. Continuing anyway... check VM logs")
                    remaining_vms.append(cluster.vms[i])
        #ENDFOR - Attempt to destroy each remaining VM in the system

        self.resource_pool.save_persistence()

        # Print list of VMs cloud scheduler failed to destroy before exit.
        if (remaining_vms != []):
            log.error("The following VMs could not be destroyed properly:")
            for vm in remaining_vms:
                log.error("VM: %s, ID: %s" % (vm.name, vm.id))

    def vm_creation(self, job, good_resources):
        # Create an optional customization metadata file
        customizations = []
        create_ret = None
        if config.condor_host != "localhost" and config.condor_context_file:
            customizations.append((config.condor_host, config.condor_context_file))

        if config.cert_file:
            file_contents = open(config.cert_file).read()

            if config.cert_file_on_vm:
                file_location = config.cert_file_on_vm
            else:
                file_location = config.cert_file

            customizations.append((file_contents, file_location))

        if config.key_file:
            file_contents = open(config.key_file).read()

            if config.key_file_on_vm:
                file_location = config.key_file_on_vm
            else:
                file_location = config.key_file

            customizations.append((file_contents, file_location))


        for resource in good_resources:
            # Print details of the resource selected
            log.debug("Booting VM for job %s on %s:" % (job.id, resource.name))
            resource.log()

            if resource.__class__.__name__ == "NimbusCluster":
                args = {'vm_name':job.req_image,
                        'vm_type':job.req_vmtype,
                        'vm_networkassoc':job.req_network,
                        'vm_cpuarch':job.req_cpuarch,
                        'vm_image':job.req_imageloc,
                        'vm_mem':job.req_memory,
                        'vm_cores':job.req_cpucores,
                        'vm_storage':job.req_storage,
                        'customization':customizations,
                        'vm_keepalive':job.keep_alive}
                create_ret = resource.vm_create(**args)
            elif resource.__class__.__name__ == "EC2Cluster":
                args = {'vm_name':job.req_image,
                        'vm_type':job.req_vmtype,
                        'vm_networkassoc':job.req_network,
                        'vm_cpuarch':job.req_cpuarch,
                        'vm_image':job.req_ami,
                        'vm_mem':job.req_memory,
                        'vm_cores':job.req_cpucores,
                        'vm_storage':job.req_storage,
                        'customization':customizations,
                        'vm_keepalive':job.keep_alive,
                        'instance_type':job.instance_type,
                        'maximum_price':job.maximum_price}
                create_ret = resource.vm_create(**args)

            # If the VM create fails, try again on another resource
            if (create_ret != 0):
                log.debug("Creating VM for job %s failed on %s. " % (job.id, resource.name))
                continue

            # If the vm create didn't fail, break out of the loop
            break

        # If VM creation fails for user-job on all resources move to next user
        if create_ret != 0:
            log.debug("None of the resources could boot a vm for job %s. " % job.id + \
                      "Leaving %s's jobs unscheduled, moving on to next user" % job.user)
        return create_ret



    def remove_idle_machines(self, machineList, to_remove):
        for vmtype, count in to_remove.iteritems():
            log.debug("Attemping to remove %i VMs of type %s" % (count, vmtype))
            criteria = {'VMType': vmtype, 'State': 'Unclaimed', 'Activity': 'Idle'}
            unused_vms_of_type = self.resource_pool.find_in_where(machineList, criteria)
            num_to_shutdown = 0
            len_unused = len(unused_vms_of_type)
            # Make sure we don't try to shutdown more than is possible
            if len_unused == 0:
                log.debug("Could not find any VMs to shutdown")
            elif len_unused >= count:
                num_to_shutdown = count
            elif len_unused < count:
                num_to_shutdown = len_unused
                
            for x in range(0, num_to_shutdown):
                log.debug("Name of Condor Machine to shutdown: %s" % unused_vms_of_type[x]['Name'])
                condor_names = unused_vms_of_type[x]['Name'].split('.')
                condor_name = condor_names[0]
                # Track if machine found or not so can break from loop early
                found_vm = False
                for cluster in self.resource_pool.resources:
                    for vm in cluster.vms:
                        log.debug("vm hostname: %s, condor name: %s" % (vm.hostname, condor_name))
                        if vm.hostname.split(".")[0] == condor_name and vm.vmtype == vmtype:
                            found_vm = True
                            if vm.idle_start:
                                # Check that enough time has passed to shutdown
                                now = int(time.time())
                                if now - vm.idle_start > vm.keep_alive:
                                    log.info("VM of type %s no longer required for remaining jobs" % vm.vmtype)
                                    vm.log_dbg()
                                    destroy_ret = cluster.vm_destroy(vm)
                                    if destroy_ret != 0:
                                        log.error("Destroying VM failed in attempt to clear uneeded VM. Leaving VM.")
                                    else:
                                        break
                            else:
                                vm.idle_start = int(time.time())
                                break
                    if found_vm:
                        break


class Cleanup(threading.Thread):
    """
    Cleanup - Periodically syncs the new and scheduled job queues to better
              reflect the state of the jobs
    """

    IDLE = 1
    RUNNING = 2

    def __init__(self, resource_pool, job_pool):
        threading.Thread.__init__(self)
        self.job_pool = job_pool
        self.resource_pool = resource_pool
        self.quit = False
        self.polling_interval = 5 # seconds

    def stop(self):
        log.debug("Waiting for cleanup loop to end")
        self.quit = True

    def run(self):
        log.info("Starting Cleanup Thread...")

        while not self.quit:
            log.debug("Syncing job queues")

            # Check through new jobs for running jobs and move to sched
            if not self.job_pool.write_lock.acquire():
                log.debug("cleanup couldn't get a write lock on the job lists")
            else:
                try:
                    for user in self.job_pool.new_jobs.keys():
                        for job in reversed(self.job_pool.new_jobs[user]):
                            if job.job_status == self.RUNNING:
                                self.job_pool.schedule(job)
                    vms = self.resource_pool.get_vmtypes_count_internal()
                    job_req_count = {}
                    for user in self.job_pool.sched_jobs.keys():
                        for job in self.job_pool.sched_jobs[user]:
                            if job.req_vmtype in job_req_count:
                                job_req_count[job.req_vmtype] += 1
                            else:
                                job_req_count[job.req_vmtype] = 1
                    for user in self.job_pool.sched_jobs.keys():
                        for job in reversed(self.job_pool.sched_jobs[user]):
                            if job.job_status == self.IDLE and (job.req_vmtype not in vms.keys() or (vms[job.req_vmtype] < job_req_count[job.req_vmtype])):
                                self.job_pool.unschedule(job)
                    
                finally:
                    self.job_pool.write_lock.release()

            req_vmtypes = self.job_pool.get_required_vmtypes()
            for cluster in self.resource_pool.resources:
                for vm in reversed(cluster.vms):
                    if vm.vmtype not in req_vmtypes:
                        destroy_ret = cluster.vm_destroy(vm)
                        if destroy_ret != 0:
                            log.error("(cleanup) - Destroying VM failed in attempt to clear uneeded VM. Leaving VM.")

            log.debug("Cleanup waiting %ds..." % self.polling_interval)
            sleep_tics = self.polling_interval
            while (not self.quit) and sleep_tics > 0:
                time.sleep(1)
                sleep_tics -= 1

        log.debug("Exiting cleanup thread")

class GetClouds(threading.Thread):
    """
    GetClouds - Periodically syncs the cluster resources with a redis store
                being updated by the cloud-aggregator monitoring package
    """


    def __init__(self, resource_pool):
        threading.Thread.__init__(self)
        self.resource_pool = resource_pool
        self.quit = False
        self.polling_interval = 10 # secondsgetCloudsClient
        #self.getclouds = getCloudsClient()

    def stop(self):
        log.debug("Waiting for getclouds loop to end")
        self.quit = True

    def run(self):
        log.info("Starting getclouds Thread...")

        while not self.quit:
            log.debug("fetching information from cloud-aggregator")
            #cloud_info = self.getclouds.getCloudsView()
            #for cloud in cloud_info:
                ## Find cluster that matches this cloud
                #for cluster in self.resource_pool.resources:
                    #if cloud['Service']['HostName'] == cluster.network_address.split('.')[0]:
                        ## Found it
                        #slots = 0
                        #for pool in cloud['NetworkPools']:
                            #slots += int(pool['AvailableIPs'])
                        #cluster.vm_slots = slots
                        #break


            log.debug("getclouds waiting %ds..." % self.polling_interval)
            sleep_tics = self.polling_interval
            while (not self.quit) and sleep_tics > 0:
                time.sleep(1)
                sleep_tics -= 1

        log.debug("Exiting getclouds thread")
##
## Functions
##

def main():
    # Log entry message (for timestamp in log)
    log.info("Cloud Scheduler starting...")

    # Create a parser and process commandline arguments
    version_str = "Cloud Scheduler " + version.version
    parser = OptionParser(version=version_str)
    set_options(parser)
    (cli_options, args) = parser.parse_args()

    # Look for global configuration file, and initialize config
    if (cli_options.config_file):
        config.setup(path=cli_options.config_file)
    else:
        config.setup()

    # Set up logging
    log.setLevel(utilities.LEVELS[config.log_level])
    log_formatter = logging.Formatter("%(asctime)s - %(levelname)s " \
                                      "- %(message)s")
    if config.log_stdout:
        stream_handler = logging.StreamHandler()
        stream_handler.setFormatter(log_formatter)
        log.addHandler(stream_handler)

    if config.log_location:
        file_handler = None
        if config.log_max_size:
            file_handler = logging.handlers.RotatingFileHandler(
                                            config.log_location,
                                            maxBytes=config.log_max_size)
        else:
            file_handler = logging.handlers.RotatingFileHandler(
                                            config.log_location,)

        file_handler.setFormatter(log_formatter)
        log.addHandler(file_handler)

    if not config.log_location and not config.log_stdout:
        null_handler = utilities.NullHandler()
        log.addHandler(null_handler)


    # Command line options take precedence, so replace config file
    # option with command line option
    if cli_options.cloud_conffile:
        config.cloud_resource_config = cli_options.cloud_conffile

    # If the neither the cloud conffile or the MDS server are passed to obtain
    # initial cluster information, print usage and exit the system.
    if (not config.cloud_resource_config) and (not cli_options.mds_server):
        print "ERROR - main - No cloud or cluster information sources provided"
        parser.print_help()
        sys.exit(1)

    # Create a job pool
    job_pool = job_management.JobPool("Job Pool")

    # Create a resource pool
    cloud_resources = cloud_management.ResourcePool(config.cloud_resource_config)

    # Log the resource pool
    cloud_resources.log_pool()

    # We maintain two lists of threads, service and info. Service threads
    # are neccessary for cloud scheduler to actually do anything, and the
    # info threads are to give the user information about what's going on.

    service_threads = []
    info_threads = []

    # Start the cloud scheduler info server for RPCs
    info_serv = info_server.CloudSchedulerInfoServer(cloud_resources, job_pool)
    info_serv.daemon = True
    info_threads.append(info_serv)

    # Create the Job Polling thread
    job_poller = JobPoller(job_pool)
    service_threads.append(job_poller)

    # Create the VM Polling thread
    vm_poller = VMPoller(cloud_resources)
    service_threads.append(vm_poller)

    # Create the Scheduling thread
    scheduler = Scheduler(cloud_resources, job_pool)
    service_threads.append(scheduler)

    # Create the Cleanup Thread
    cleaner = Cleanup(cloud_resources, job_pool)
    service_threads.append(cleaner)

    # Create the GetClouds Thread if wanted
    if config.getclouds:
        getclouds = GetClouds(cloud_resources)
        service_threads.append(getclouds)

    # Set SIGTERM (kill) handler
    signal.signal(signal.SIGTERM, term_handler)

    # Set SIGUSR1 (reconfig) handler
    reconfig_handler = make_reconfig_handler(cloud_resources)
    signal.signal(signal.SIGUSR1, reconfig_handler)


    # Start all the threads
    for thread in info_threads:
        thread.start()

    for thread in service_threads:
        thread.start()

    should_be_running = True

    # Wait for keyboard input to exit the cloud scheduler
    try:
        while True:
            for thread in service_threads:
                if not thread.isAlive():
                    break
            time.sleep(1)
    except (SystemExit, KeyboardInterrupt):
        log.info("Caught a signal that someone wants me to quit!")
        should_be_running = False

    if should_be_running:
        log.error("Whoops. Wasn't expecting to exit. Did a thread crash?")

    log.info("Cloud Scheduler quitting normally. (It might take a while, don't panic!)")

    # Kill all the service threads, then the info_server
    for thread in service_threads:
        thread.stop()

    for thread in service_threads:
        thread.join()

    for thread in info_threads:
        thread.stop()

    for thread in info_threads:
        thread.join()

    log.info("Cloud Scheduler stopped. Bye!")
    sys.exit()


def term_handler(signal, handler):
    log.info("Recieved SIGTERM signal")
    sys.exit()

def make_reconfig_handler(resource_pool):
    """
    make_reconfig_handler - make a signal handler that can reconfig the passed
                            ResourcePool object
    """
    def reconfig_handler(signal, handler):
        log.info("Recieved SIGUSR1 (reconfig) signal. Reloading resources file...")
        resource_pool.setup()

    return reconfig_handler

# Sets the command-line options for a passed in OptionParser object (via optparse)
def set_options(parser):

    # Option attributes: action, type, dest, help. See optparse documentation.
    # Defaults: action=store, type=string, dest=[name of the option] help=none
    parser.add_option("-f", "--config-file", dest="config_file",
                      metavar="FILE",
                      help="Designate a config file for Cloud Scheduler")
    parser.add_option("-c", "--cloud-config", dest="cloud_conffile",
                      metavar="FILE",
                      help="Designate a config file from which cloud cluster "
                           "information is obtained")

    parser.add_option("-m", "--MDS", dest="mds_server", metavar="SERVER",
                      help="Designate an MDS server from which cloud cluster "
                           "information is obtained")


##
## Main Functionality
##

main()
