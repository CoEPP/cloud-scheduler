#!/usr/bin/env python
# vim: set expandtab ts=4 sw=4:

# Copyright (C) 2009 University of Victoria
# You may distribute under the terms of either the GNU General Public
# License or the Apache v2 License, as specified in the README file.

## Auth: Duncan Penfold-Brown. 6/15/2009

## CLOUD SCHEDULER
##
## The main body for the cloud scheduler, that encapsulates and organizes
## all cloud scheduler functionality.
##
## Using optparse for command line options (http://docs.python.org/library/optparse.html)
##


## Imports

import sys
import logging
import getopt
import threading
import time   # for testing purposes only (sleeps)
import string # for debugging purposes
from optparse import OptionParser
import ConfigParser

import cloudscheduler.cloud_management as cloud_management
import cloudscheduler.job_management as job_management
import cloudscheduler.info_server as info_server
import cloudscheduler.config as config

## GLOBAL VARIABLES

usage_str = "cloud_scheduler [-f FILE | --config-file] [-c FILE | --cluster-config FILE] [-m SERVER | --MDS SERVER]"
version_str = "Cloud Scheduler v 0.1"


## LOGGING SETUP

log = logging.getLogger("CloudLogger")
LEVELS = {'DEBUG': logging.DEBUG,
          'INFO': logging.INFO,
          'WARNING': logging.WARNING,
          'ERROR': logging.ERROR,
          'CRITICAL': logging.CRITICAL,}
class NullHandler(logging.Handler):
    def emit(self, record):
        pass

## Thread Bodies

# Polling:
# The resource & running vm polling thread. Inherits from Thread class.
# Polling thread will iterate through the resource pool, updating resource
#   status based on vm_poll calls to each vm in a cluster's 'vms' list (of
#   running vms)
# Constructed with argument 'resource_pool'
class PollingTh(threading.Thread):

    def __init__(self, resource_pool):
        threading.Thread.__init__(self)
        self.resource_pool = resource_pool

    def run(self):
        # TODO: Implement polling thread functionality here.
        log.debug("Poll - Starting polling thread...")

# Scheduling:
# Scheduling thread will match jobs to available resources and start vms
# (for now, will contain test create/destroy functions)
class SchedulingTh(threading.Thread):

    def __init__(self, resource_pool, job_pool):
        threading.Thread.__init__(self)
        self.resource_pool = resource_pool
        self.job_pool      = job_pool
        self.quit          = False

    def stop(self):
        log.debug("Wating for scheduling loop to end")
        self.quit = True

    def run(self):
        log.debug("Sched - Starting scheduling thread...")

        ########################################################################
        ## Full scheduler loop
        ########################################################################

        while (not self.quit):
            log_with_line("Scheduler Loop")

            ## Query the job pool to get new unscheduled jobs
            # Populates the 'jobs' and 'scheduled_jobs' lists appropriately
            self.job_pool.job_querySOAP()

            ## Attempt to schedule all unscheduled jobs
            log.info("Schedule all queued jobs")
            for job in self.job_pool.jobs:

                log.debug("(Scheduler) - Attempting to schedule job %s" % job.get_id())

                # Find a resource that matches the job's requirements
                target_cluster = self.resource_pool.get_resourceFF(job.req_network, \
                  job.req_cpuarch, job.req_memory)

                # If no job fits, leave job in list and continue to next job
                if (target_cluster == None):
                    log.info("Scheduler - No resource to match job: %s" % job.get_id())
                    log.info("Scheduler - Leaving job unscheduled, moving to next job")
                    continue

                # Print details of the resource selected
                log.info("Scheduler - Open resource selected:")
                target_cluster.log()

                # Start VM with job requirements on the selected resource
                create_ret = target_cluster.vm_create(job.req_image,
                        job.req_vmtype, job.req_network, job.req_cpuarch,
                        job.req_imageloc, job.req_memory, job.req_cpucores,
                        job.req_storage)

                # If the VM create fails, continue to the next job
                if (create_ret != 0):
                    log.info("Scheduler - Creating VM for job %s failed" % job.get_id())
                    log.info("Scheduler - VM Create failed on cluster: ")
                    target_cluster.log()
                    log.info("Scheduler - Leaving job unscheduled, moving to next job")
                    continue

                # Mark job as scheduled
                self.job_pool.schedule(job)

            #ENDFOR - Attempt to schedule each job in the job pool

            ## Wait for a number of seconds
            log_with_line("Waiting")
            log.info("Scheduler - Waiting...")
            time.sleep(3)

            ## Clear all un-needed VMs from the system
            # NOTE: This could be incorporated into the poll loop below.

            # Gather all system jobs' required VM types
            log.info("Scheduler - Gathering required VM types from system jobs.")
            required_vmtypes = []
            for job in (self.job_pool.jobs + self.job_pool.scheduled_jobs):
                if job.req_vmtype not in required_vmtypes:
                    required_vmtypes.append(job.req_vmtype)
            log.debug("Scheduler - Required VM types: " + ", ".join(required_vmtypes))

            # Remove all VMs with a type not required by current system jobs
            log.info("Scheduler - Removing unneeded VMs...")
            for cluster in self.resource_pool.resources:
                # Use alternative loop structure to avoid unsafe remove operation
                # (move backwards through the list - removes don't affect later list elements)
                i = len(cluster.vms)
                while (i != 0):
                    i = i-1
                    # If VM is not required, destroy it
                    if (cluster.vms[i].vmtype not in required_vmtypes):
                        log.debug("Scheduler - VM type not required. Destroying VM:")
                        cluster.vms[i].log()
                        destroy_ret = cluster.vm_destroy(cluster.vms[i])
                        if (destroy_ret != 0):
                            log.error("(Scheduler) - Destroying VM failed in attempt to clear un-needed VM. Leaving VM.")
                            continue
                #ENDWHILE - Check all VMs on a cluster

            #ENDFOR - Clear all unneeded VMs from the system

            ## Poll all remaining system VMs
            # TODO: Fix bug here: this loops polls every running VM twice
            log.info("Scheduler - Polling all running VMs...")
            for cluster in self.resource_pool.resources:
                for vm in cluster.vms:
                    ret_state = cluster.vm_poll(vm)

                    # Print polled VM's state and details
                    log.info("Scheduler - Polled VM: ")
                    vm.log()
                    log.debug("(Scheduler) - VM in '%s' state" % ret_state)

                    # If the VM is in an error state, manually recreate it
                    if ret_state == "Error":
                        log.debug("(Scheduler) - VM in error state. Recreating...")

                        # Store all VM fields
                        vm_name = vm.name
                        vm_type = vm.vmtype
                        vm_network = vm.network
                        vm_cpuarch = vm.cpuarch
                        vm_imageloc = vm.imagelocation
                        vm_mem = vm.memory
                        vm_cores = vm.cpucores
                        vm_storage = vm.storage

                        # Destroy the VM
                        destroy_ret = cluster.vm_destroy(vm)
                        if (destroy_ret != 0):
                            log.error("(Scheduler) - Destroying VM failed. Leaving VM in error state.")
                            continue
                        # Find an available resource to recreate on
                        target_rsrc = self.resource_pool.get_resourceFF(vm_network, vm_cpuarch, vm_mem)
                        if (target_rsrc == None):
                            log.error("(Scheduler) - No resource found for recreation. Aborting recreate.")
                            continue
                        # Recreate the VM on the new resource
                        log.debug("(Scheduler) - Open resource selected:")
                        target_rsrc.log()
                        create_ret = target_rsrc.vm_create(vm_name, vm_network, vm_cpuarch, vm_imageloc, vm_mem)
                        if (create_ret != 0):
                            log.error("(Scheduler) - Recreating VM failed. Leaving VM in error state.")
                            continue
                    # ENDIF - if VM in error state

                    ## CANNOT USE recreate or reboot because of poll loop bug.
                    ## If the VM is in an error state, recreate it!
                    #if ret_state == "Error":
                    #   print "(Scheduler) - VM in error state. Recreating..."
                    #   recreate_ret = cluster.vm_recreate(vm)

                        # If recreate fails, leave VM in error state (tbdestroyed)
                    #   if (recreate_ret != 0):
                    #       print "(Scheduler) - Recreating VM failed. Leaving" +\
                    #         "VM in error state"
                    #       continue

            #ENDFOR - Poll each running VM in the resource pool

        #ENDFOR - End of the main scheduler loop

        # Exit the scheduling thread - clean up VMs and exit
        log.debug("Exiting scheduler thread")

        # Destroy all VMs and finish
        log.debug("Destroying all remaining VMs :-(")
        for cluster in self.resource_pool.resources:
            for vm in cluster.vms:
                log.debug("(Scheduler) - Destroying VM:")
                vm.log()

                destroy_ret = cluster.vm_destroy(vm)
                if destroy_ret != 0:
                    log.debug("(Scheduler) - Destroying VM failed. Continuing " +\
                      "anyway... check VM logs")

        #ENDFOR - Attempt to destroy each remaining VM in the system


##
## Functions
##

def main():

    # Create a parser and process commandline arguments
    parser = OptionParser(usage=usage_str, version=version_str)
    set_options(parser)
    (cli_options, args) = parser.parse_args()

    # Look for global configuration file, and initialize config
    if (cli_options.config_file):
        config.setup(path=cli_options.config_file)
    else:
        config.setup()

    # Set up logging
    log.setLevel(LEVELS[config.log_level])
    log_formatter = logging.Formatter("%(asctime)s - %(levelname)s " \
                                      "- %(message)s")
    if config.log_stdout:
        stream_handler = logging.StreamHandler()
        stream_handler.setFormatter(log_formatter)
        log.addHandler(stream_handler)

    if config.log_location:
        file_handler = None
        if config.log_max_size:
            file_handler = logging.handlers.RotatingFileHandler(
                                            config.log_location,
                                            maxBytes=config.log_max_size)
        else:
            file_handler = logging.handlers.RotatingFileHandler(
                                            config.log_location,)

        file_handler.setFormatter(log_formatter)
        log.addHandler(file_handler)

    if not config.log_location and not config.log_stdout:
        null_handler = NullHandler()
        log.addHandler(null_handler)


    # Command line options take precedence, so replace config file
    # option with command line option
    if cli_options.cloud_conffile:
        config.cloud_resource_config = cli_options.cloud_conffile

    # If the neither the cloud conffile or the MDS server are passed to obtain
    # initial cluster information, print usage and exit the system.
    if (not config.cloud_resource_config) and (not cli_options.mds_server):
        print "ERROR - main - No cloud or cluster information sources provided"
        parser.print_help()
        sys.exit(1)

    # Create a resource pool
    cloud_resources = cloud_management.ResourcePool("Resource Pool")

    # Create a job pool
    job_pool = job_management.JobPool("Job Pool")

    # Read in the config file, if we're using one
    if config.cloud_resource_config:
        if read_cloud_config(config.cloud_resource_config, cloud_resources):
            print "ERROR - Reading cloud configuration file failed. Exiting..."
            sys.exit(1)

    # TODO: Add code to query an MDS to get initial cluster/cloud information

    # Log the resource pool
    cloud_resources.log_pool()

    # TODO: Resolve issue of atomicity / reliability when 2 threads are working
    #       on the same resource pool data. Does it matter (best effort!)?

    # Start the cloud scheduler info server for RPCs
    info_serv = info_server.CloudSchedulerInfoServer(cloud_resources)
    info_serv.daemon = True
    info_serv.start()
    log.debug("Started Cloud Scheduler info server...")

    # Create the Polling thread (pass resource pool)
    poller = PollingTh(cloud_resources)
    poller.start()

    # Create the Scheduling thread (pass resource pool)
    scheduler = SchedulingTh(cloud_resources, job_pool)
    scheduler.start()

    log.debug("Scheduling and Polling threads started.")

    # Wait on the scheduler to finish before exiting main
    log.debug("Waiting for the scheduler to finish...")

    # Wait for keyboard input to exit the cloud scheduler
    try:
        while scheduler.isAlive():
            time.sleep(2)
    except (SystemExit, KeyboardInterrupt):
        log.info("Exiting normally due to KeyboardInterrupt or SystemExit")

    # Clean up out threads (shuts down all running VMs)
    scheduler.stop()
    info_serv.stop()
    sys.exit()


# Sets the command-line options for a passed in OptionParser object (via optparse)
def set_options(parser):

    # Option attributes: action, type, dest, help. See optparse documentation.
    # Defaults: action=store, type=string, dest=[name of the option] help=none
    parser.add_option("-f", "--config-file", dest="config_file",
                      metavar="FILE",
                      help="Designate a config file for Cloud Scheduler")
    parser.add_option("-c", "--cloud-config", dest="cloud_conffile",
                      metavar="FILE",
                      help="Designate a config file from which cloud cluster "
                           "information is obtained")

    parser.add_option("-m", "--MDS", dest="mds_server", metavar="SERVER",
                      help="Designate an MDS server from which cloud cluster "
                           "information is obtained")

# Reads in a cmdline passed configuration file containing cloud cluster information
# Stores cluster information in the ResourcePool parameter rsrc_pool
# (see the sample_cloud example configuration file for more information)
def read_cloud_config(config_file, rsrc_pool):

    log.debug("Attempting to read cloud configuration file: " + config_file)

    cloud_config = ConfigParser.ConfigParser()
    cloud_config.read(config_file)


    # Read in config file, parse into Cluster objects
    for cluster in cloud_config.sections():

        # Create a new cluster according to cloud_type
        if cloud_config.get(cluster, "type") == "Nimbus":
            new_cluster = cloud_management.NimbusCluster(name = cluster,
                           host = cloud_config.get(cluster, "host"),
                           type = cloud_config.get(cluster, "type"),
                           memory = map(int, cloud_config.get(cluster, "memory").split(",")),
                           cpu_archs = cloud_config.get(cluster, "cpu_archs").split(","),
                           networks = cloud_config.get(cluster, "networks").split(","),
                           vm_slots = cloud_config.getint(cluster, "vm_slots"),
                           cpu_cores = cloud_config.getint(cluster, "cpu_cores"),
                           storage = cloud_config.getint(cluster, "storage"),
                           )

        elif cloud_config.get(cluster, "type") == "OpenNebula":
            new_cluster = cloud_management.Cluster(name = cluster,
                           host = cloud_config.get(cluster, "host"),
                           type = cloud_config.get(cluster, "type"),
                           memory = map(int, cloud_config.get(cluster, "memory")),
                           cpu_archs = cloud_config.get(cluster, "cpu_archs").split(","),
                           networks = cloud_config.get(cluster, "networks").split(","),
                           vm_slots = cloud_config.getint(cluster, "vm_slots"),
                           cpu_cores = cloud_config.getint(cluster, "cpu_cores"),
                           storage = cloud_config.getint(cluster, "storage"),
                           )

        elif cloud_config.get(cluster, "type") == "Eucalyptus":
            new_cluster = cloud_management.Cluster(name = cluster,
                           host = cloud_config.get(cluster, "host"),
                           type = cloud_config.get(cluster, "type"),
                           memory = map(int, cloud_config.get(cluster, "memory")),
                           cpu_archs = cloud_config.get(cluster, "cpu_archs").split(","),
                           networks = cloud_config.get(cluster, "networks").split(","),
                           vm_slots = cloud_config.getint(cluster, "vm_slots"),
                           cpu_cores = cloud_config.getint(cluster, "cpu_cores"),
                           storage = cloud_config.getint(cluster, "storage"),
                           )



        # Add the new cluster to a resource pool
        rsrc_pool.add_resource(new_cluster)

    log.debug("Cloud configuration read succesfully from " + config_file )
    return (0)


# logs readable lined lines across the screen with message
def log_with_line(msg):
    msg_len = len(msg)
    fill = "-" * (40-msg_len)
    log.debug("-----"+msg+fill)


##
## Main Functionality
##

main()
